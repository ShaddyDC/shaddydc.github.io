+++
title = "Newcomb's empty box"
date = 2026-01-28T21:33:29+01:00
description = "What if the prediction engine doesn't see you're a good guy?"
tags = [
"philosophy",
"newcombs-problem",
]
+++

I have written about Newcomb's Problem [before](../newcombs-problem).
Because the world is small, you keep stumbling over the same topics.
So a couple of days ago I watched a Computerphile video about
[LLMs and Newcomb's Problem](https://www.youtube.com/watch?v=bdbhKoypnFI).
They use a box of $50 that may or may not be filled depending
on whether the predictor, let's call it oracle,
thinks you'll also open the other box with a certain $5.

For some reason, in my mind the choice was always between a certain
$50 and an uncertain $5 or $55 for opening both boxes.
But of course, if you don't have faith in the oracle's accuracy,
then you may end up with $0 if you pick the one box but
it thought you would open both.

I suppose that that isn't a big problem in the classic scenario
where the oracle is known to be very accurate, but it helps me
understand better why people would consider to two-box, I think.

